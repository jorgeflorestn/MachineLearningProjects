{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6dff10e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "COEFFS: np.ndarray = np.array([2, 15])\n",
    "INIT_VALUE = -10\n",
    "END_VALUE = 10\n",
    "ITERATIONS: int = 500\n",
    "LEARNING_RATE: float = 0.05\n",
    "\n",
    "\n",
    "def eval_poly(coeffs: np.ndarray, x: float) -> float:\n",
    "    total: float = 0\n",
    "    for power, coeff in enumerate(coeffs[::-1]):\n",
    "        total += (x**power) * coeff\n",
    "    return total\n",
    "\n",
    "\n",
    "def gradient_descent(\n",
    "    x_values: np.ndarray,\n",
    "    y_values: np.ndarray,\n",
    "    no_weights: int,\n",
    "    learning_rate: float,\n",
    "    iterations: int,\n",
    "    batch_size: int = -1,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    if batch_size == -1:\n",
    "        batch_size = x_values.size\n",
    "\n",
    "    x_c = np.c_[np.ones((x_values.size, no_weights - 1)), x_values]\n",
    "    weights = np.random.randn(no_weights, 1)\n",
    "    error_log = np.zeros(iterations)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        x_c_batch, y_values_batch = zip(\n",
    "            *random.sample(list(zip(x_c, y_values)), batch_size)\n",
    "        )\n",
    "\n",
    "        x_c_batch = np.array(list(x_c_batch))\n",
    "        y_values_batch = np.array(list(y_values_batch))\n",
    "\n",
    "        multi = np.array(x_c_batch @ weights - y_values_batch)\n",
    "        multi_squared = multi**2\n",
    "\n",
    "        error_log[i] = (1 / (2 * batch_size)) * (multi_squared).sum()\n",
    "\n",
    "        gradients = (1 / batch_size) * (x_c_batch.T @ multi)\n",
    "\n",
    "        weights -= learning_rate * gradients\n",
    "\n",
    "    return weights[::-1], error_log\n",
    "\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    data_size = END_VALUE - INIT_VALUE + 1\n",
    "    no_weights = COEFFS.size\n",
    "\n",
    "    x_values = np.linspace(INIT_VALUE, END_VALUE, data_size).reshape(data_size, 1)\n",
    "    y_values = np.array(\n",
    "        [eval_poly(COEFFS, x) * random.randint(90, 110) / 100 for x in x_values]\n",
    "    ).reshape(data_size, 1)\n",
    "\n",
    "    #  === Batch ===\n",
    "    batch_result_coeffs, batch_error_log = gradient_descent(\n",
    "        x_values, y_values, no_weights, LEARNING_RATE, ITERATIONS\n",
    "    )\n",
    "    batch_y_predicted = np.array([eval_poly(batch_result_coeffs, x) for x in x_values])\n",
    "\n",
    "    #  === Stochastic ===\n",
    "    stochastic_result_coeffs, stochastic_error_log = gradient_descent(\n",
    "        x_values, y_values, no_weights, 0.01, ITERATIONS, batch_size=1\n",
    "    )\n",
    "    stochastic_y_predicted = np.array(\n",
    "        [eval_poly(stochastic_result_coeffs, x) for x in x_values]\n",
    "    )\n",
    "\n",
    "    #  === Mini-batch ===\n",
    "    mini_batch_result_coeffs, mini_batch_error_log = gradient_descent(\n",
    "        x_values,\n",
    "        y_values,\n",
    "        no_weights,\n",
    "        LEARNING_RATE,\n",
    "        ITERATIONS,\n",
    "        batch_size=int(x_values.size * 0.50),\n",
    "    )\n",
    "    mini_batch_y_predicted = np.array(\n",
    "        [eval_poly(mini_batch_result_coeffs, x) for x in x_values]\n",
    "    )\n",
    "\n",
    "    print(\"Expected result: {}\".format(COEFFS))\n",
    "    print(\n",
    "        \"Batch calculated result: {}\".format(batch_result_coeffs.reshape(1, no_weights))\n",
    "    )\n",
    "    print(\n",
    "        \"Stochastic calculated result: {}\".format(\n",
    "            stochastic_result_coeffs.reshape(1, no_weights)\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Mini-batch calculated result: {}\".format(\n",
    "            mini_batch_result_coeffs.reshape(1, no_weights)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig, _ = plt.subplots(3, 2)\n",
    "    fig.tight_layout()  # type: ignore\n",
    "\n",
    "    #  === Batch ===\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(x_values, y_values, \"b.\", label=\"Input data\")\n",
    "    plt.plot(x_values, batch_y_predicted, \"r\", label=\"Predicted data\")\n",
    "    plt.title(\"Batch: x vs y\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(range(ITERATIONS), batch_error_log)\n",
    "    plt.title(\"Batch: iterations vs error\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Error\")\n",
    "\n",
    "    #  === Stochastic ===\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(x_values, y_values, \"b.\", label=\"Input data\")\n",
    "    plt.plot(x_values, stochastic_y_predicted, \"r\", label=\"Predicted data\")\n",
    "    plt.title(\"Stochastic: x vs y\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.plot(range(ITERATIONS), stochastic_error_log)\n",
    "    plt.title(\"Stochastic: iterations vs error\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Error\")\n",
    "\n",
    "    #  === Mini-batch ===\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.plot(x_values, y_values, \"b.\", label=\"Input data\")\n",
    "    plt.plot(x_values, mini_batch_y_predicted, \"r\", label=\"Predicted data\")\n",
    "    plt.title(\"Mini-batch: x vs y\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.plot(range(ITERATIONS), mini_batch_error_log)\n",
    "    plt.title(\"Mini-batch: iterations vs error\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.show()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a96d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
