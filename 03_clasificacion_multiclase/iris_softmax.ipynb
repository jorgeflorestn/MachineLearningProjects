{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación multiclase softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación softmax es una generalización de la regresión logística binaria, donde en vez de dividir o separar mediante un valor delimitante se asignan valores de probabilidad mediante la 'normalización' de valores de salida o las clases mediante la funcion *softmax* o también conocido como *función exponencial normalizada*\n",
    "\n",
    "La función se define de l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import Bunch\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "#  logging.disable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo de teoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de preparacion de datos y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(target: np.ndarray) -> np.ndarray:\n",
    "    n_classes: int = np.unique(target).shape[0]\n",
    "    y_encode: np.ndarray = np.zeros((target.shape[0], n_classes))\n",
    "    for idx, val in enumerate(target):\n",
    "        y_encode[idx, val] = 1.0\n",
    "    return y_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(\n",
    "    data: np.ndarray, target: np.ndarray, eta: float = 0.55, iterations: int = 100000\n",
    ") -> np.ndarray:\n",
    "    m = len(target)\n",
    "    logging.info(f\"target: {m}\")\n",
    "\n",
    "    theta = np.random.randn(data.shape[1], target.shape[1])\n",
    "\n",
    "    logging.info(f\"theta: {theta}\")\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        gradients = (1 / m) * (data.T @ (sigmoid(data @ theta) - target))\n",
    "        theta = theta - eta * gradients\n",
    "\n",
    "    logging.info(f\"theta: {theta}\")\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(\n",
    "    sepal_length: float,\n",
    "    sepal_width: float,\n",
    "    petal_length: float,\n",
    "    petal_width: float,\n",
    "    weights: np.ndarray,\n",
    ") -> list[int]:\n",
    "    list1 = [0, 0, 0]\n",
    "\n",
    "    for i in range(len(list1)):\n",
    "        a0 = weights.T[i][0]\n",
    "        a1 = weights.T[i][1]\n",
    "        a2 = weights.T[i][2]\n",
    "        a3 = weights.T[i][3]\n",
    "        a4 = weights.T[i][4]\n",
    "        list1[i] = np.exp(\n",
    "            a0 + a1 * sepal_length + a2 * sepal_width + a3 * petal_length + a4 * petal_width\n",
    "        )\n",
    "\n",
    "    maxP = np.argmax([z / sum(list1) for z in list1])\n",
    "\n",
    "    pred = [0, 0, 0]\n",
    "\n",
    "    pred[maxP] = 1\n",
    "\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(\n",
    "    data: np.ndarray, target: np.ndarray, weights: np.ndarray\n",
    ") -> tuple[np.ndarray, float]:\n",
    "    predict_list = []\n",
    "    test_list = []\n",
    "    for i in data:\n",
    "        predict_list.append(np.argmax(model_test(i[0], i[1], i[2], i[3], weights)))\n",
    "    for j in target:\n",
    "        test_list.append(np.argmax(j))\n",
    "    num = 0\n",
    "    for k in range(len(predict_list)):\n",
    "        if predict_list[k] == test_list[k]:\n",
    "            num = num + 1\n",
    "\n",
    "    final_list: np.ndarray = np.array([predict_list, test_list], ndmin=2)\n",
    "    effi = num / len(predict_list)\n",
    "\n",
    "    return final_list, effi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de datos: Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris: Bunch = datasets.load_iris()  # type: ignore\n",
    "\n",
    "x_data: np.ndarray = iris[\"data\"]  # type: ignore\n",
    "y_data: np.ndarray = iris[\"target\"]  # type: ignore\n",
    "\n",
    "x_c: np.ndarray = np.c_[np.ones((len(x_data), 1)), x_data]\n",
    "y_c = one_hot_encoder(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos, división en split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:x_train shape: (52, 5)\n",
      "INFO:root:x_test shape: (98, 5)\n",
      "INFO:root:y_train shape: (52, 3)\n",
      "INFO:root:y_test shape: (98, 3)\n"
     ]
    }
   ],
   "source": [
    "train_test_data: list[np.ndarray] = train_test_split(x_c, y_c, train_size=0.35)  # type: ignore\n",
    "x_train, x_test, y_train, y_test = train_test_data\n",
    "\n",
    "logging.info(f\"x_train shape: {x_train.shape}\")\n",
    "logging.info(f\"x_test shape: {x_test.shape}\")\n",
    "logging.info(f\"y_train shape: {y_train.shape}\")\n",
    "logging.info(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:target: 52\n",
      "INFO:root:theta: [[ 0.01995625  0.14691127  0.23582594]\n",
      " [ 0.40811085  0.47765865 -0.49195017]\n",
      " [ 1.78964902  1.4857198  -0.99024404]\n",
      " [-0.04004406  1.80288804  0.42819982]\n",
      " [-0.0761417  -0.4166329  -1.18100824]]\n",
      "INFO:root:theta: [[  1.74882945  -1.51744812   0.17131213]\n",
      " [  4.64504527   3.63647363  -7.88769957]\n",
      " [ 14.21899524   9.87114761 -21.80501807]\n",
      " [-13.30193549  -4.26935289  19.76233218]\n",
      " [ -8.61337495 -10.28452533  17.22411744]]\n"
     ]
    }
   ],
   "source": [
    "a = model_fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Predictions: [[0 1 1 1 1 0 1 0 1 0 0 0 0 2 1 1 0 2 0 0 0 0 1 0 2 0 1 1 0 0 0 0 0 0 2 1\n",
      "  0 1 0 0 0 0 0 0 1 0 2 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      "  1 2 1 1 0 1 0 1 1 1 0 0 1 2 1 1 0 1 1 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 1 0 2 0 2 1 2 1 2 0 0 1 2 2 1 2 0 0 0 2 1 0 0 2 2 1 2 2 1 2 0\n",
      "  0 0 1 2 1 2 1 0 0 2 2 2 0 1 1 2 0 2 0 1 0 2 0 2 1 0 1 1 1 2 1 1 2 0 2 1\n",
      "  0 2 0 0 2 0 0 0 0 0 1 1 0 1 0 0 2 0 0 2 2 0 1 1 1 1]]\n",
      "INFO:root:Efficiency: 0.11224489795918367\n"
     ]
    }
   ],
   "source": [
    "predictions, efficiency = model_predict(x_test, y_test, a)\n",
    "\n",
    "logging.info(f\"Predictions: {predictions}\")\n",
    "logging.info(f\"Efficiency: {efficiency}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aprendizaje-automatico",
   "language": "python",
   "name": "aprendizaje-automatico"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
