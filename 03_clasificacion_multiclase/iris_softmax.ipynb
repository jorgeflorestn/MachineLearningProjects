{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación multiclase softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación softmax es una generalización de la regresión logística binaria, donde en vez de dividir o separar mediante un valor delimitante se asignan valores de probabilidad mediante la 'normalización' de valores de salida o las clases mediante la funcion *softmax* o también conocido como *función exponencial normalizada*\n",
    "\n",
    "La función se define de l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo de teoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de preparacion de datos y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoder(target):\n",
    "    n_classes = np.unique(target).shape[0]\n",
    "    y_encode = np.zeros((target.shape[0], n_classes))\n",
    "    for idx, val in enumerate(y):\n",
    "        y_encode[idx, val] = 1.0\n",
    "    return y_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, target, train_q = 35):\n",
    "    if (train_q < 0) or (train_q > 49): return 0, 0, 0, 0\n",
    "    \n",
    "    data_train = np.concatenate((data[0:train_q], data[50:(train_q + 50)], data[100:(train_q + 100)]))\n",
    "    data_test = np.concatenate ((data[train_q:50], data[(train_q + 50):100], data[(train_q + 100):150]))\n",
    "    target_train = np.concatenate((target[0:train_q], target[50:(train_q + 50)], target[100:(train_q + 100)]))\n",
    "    target_test = np.concatenate ((target[train_q:50], target[(train_q + 50):100], target[(train_q + 100):150]))\n",
    "    \n",
    "    return data_train, data_test, target_train, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(data, target, eta=0.55, iterations=100000):\n",
    "    m = len(target)\n",
    "    print(f'target: ', m)\n",
    "    \n",
    "    theta = np.random.randn(data.shape[1], target.shape[1])\n",
    "    print(f'theta: \\n', theta)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        gradients = (1/m) * (data.T @ (sigmoid(data @ theta) - target))\n",
    "        theta = theta - eta * gradients\n",
    "    print(f'\\n',theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(sepal_length, sepal_width, petal_length, petal_width, weights):\n",
    "    list1 = [0, 0, 0]\n",
    "    \n",
    "    for i in range(len(list1)):\n",
    "        a0 = weights.T[i][0]\n",
    "        a1 = weights.T[i][1]\n",
    "        a2 = weights.T[i][2]\n",
    "        a3 = weights.T[i][3]\n",
    "        a4 = weights.T[i][4]\n",
    "        list1[i] = np.exp(a0 + a1 * sepal_length + a2 * sepal_width + a3 * petal_length + a4 * petal_width)\n",
    "    maxP = np.argmax([z / sum(list1) for z in list1])\n",
    "    pred = [0, 0, 0]\n",
    "    pred[maxP] = 1\n",
    "    return pred\n",
    "    #return [z / sum(list1) for z in list1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(data, target, weights):\n",
    "    predict_list = []\n",
    "    test_list = []\n",
    "    for i in data:\n",
    "        predict_list.append(np.argmax(model_test(i[0], i[1], i[2], i[3], weights)))\n",
    "    for j in target:\n",
    "        test_list.append(np.argmax(j))\n",
    "    num = 0\n",
    "    for k in range(len(predict_list)):\n",
    "        if predict_list[k] == test_list[k]: num = num +1\n",
    "        \n",
    "    final_list = np.array([predict_list, test_list], ndmin=2)\n",
    "    effi = num/len(predict_list)\n",
    "    return final_list, effi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de datos: Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "X_c = np.c_[np.ones((len(X), 1)), X]\n",
    "y_c = oneHotEncoder(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos, división en split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 5) (45, 5) (105, 3) (45, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test(X_c, y_c)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  105\n",
      "theta: \n",
      " [[ 0.89524332  0.12089245  2.46052881]\n",
      " [-0.24469202 -0.1778048   1.42586629]\n",
      " [-0.78005276  1.63099264 -0.71565783]\n",
      " [-1.27720575 -1.15385804 -0.17571277]\n",
      " [ 0.88244162  0.89607265 -0.74929259]]\n",
      "\n",
      " [[  2.59196655  19.01912074 -18.13442271]\n",
      " [  3.55425772  -0.09660858  -2.45427968]\n",
      " [  7.08163481  -0.22230291  -6.72404985]\n",
      " [-10.25620885  -0.61067148   8.26010376]\n",
      " [ -3.73665257  -5.52664846  10.29252271]]\n"
     ]
    }
   ],
   "source": [
    "a = model_fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 2 2 0 2 0 2 2 0 0 2 2 2 2 0 2 2 2 2 2 2 2\n",
      "  2 2 2 2 2 2 2 2 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      "  2 2 2 2 2 2 2 2 2]] 0.35555555555555557\n"
     ]
    }
   ],
   "source": [
    "predictions, efficiency = model_predict(X_test, y_test, a)\n",
    "\n",
    "print(predictions, efficiency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
